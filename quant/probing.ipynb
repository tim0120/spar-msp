{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/timkostolansky/Dropbox (MIT)/research/spar-msp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from quant.learning_circuit import BooleanCircuit, Gate\n",
    "from quant.quant_model import MLP\n",
    "from quant.probing import HookedMLP, train_mlp, train_linear_probes, check_probe_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "width = 4\n",
    "depth = 3\n",
    "circuit = BooleanCircuit(width=width, depth=depth)\n",
    "d_input = circuit.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Training - Epoch 0/100, Train Loss: 0.26735758781433105, Test Accuracy: 94.00%\n",
      "MLP Training - Epoch 10/100, Train Loss: 7.931942491268273e-06, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 20/100, Train Loss: 1.6237265754170949e-06, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 30/100, Train Loss: 3.428196464483335e-07, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 40/100, Train Loss: 7.89447227589335e-08, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 50/100, Train Loss: 4.7104471434522566e-08, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 60/100, Train Loss: 2.1835884211895973e-08, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 70/100, Train Loss: 9.999649996927928e-09, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 80/100, Train Loss: 9.696549341242644e-09, Test Accuracy: 100.00%\n",
      "MLP Training - Epoch 90/100, Train Loss: 2.217839689677703e-09, Test Accuracy: 100.00%\n",
      "MLP training completed\n"
     ]
    }
   ],
   "source": [
    "d_mlp = 32\n",
    "n_hidden_layers = 3\n",
    "mlp = MLP(d_input, d_mlp, n_hidden_layers).to(device)\n",
    "mlp = train_mlp(mlp, circuit, num_samples=10000, num_epochs=100, batch_size=64, device=device)\n",
    "hooked_mlp = HookedMLP(mlp).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit accuracy on 64 random inputs: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def test_model(circuit: BooleanCircuit, num_samples: int):\n",
    "    inputs = torch.randint(0, 2, (num_samples, circuit.width))\n",
    "    outputs = torch.tensor([circuit(input.tolist())[0] for input in inputs]).squeeze()\n",
    "    preds = mlp(inputs.float().to(device)).round().squeeze()\n",
    "    correct = (outputs == preds).float().mean().item() * 100\n",
    "    return correct\n",
    "\n",
    "accuracy = test_model(circuit, 1024)\n",
    "print(f\"Circuit accuracy on 64 random inputs: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/timkostolansky/Dropbox (MIT)/research/spar-msp/wandb/run-20240807_172132-59mw8dea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit/runs/59mw8dea' target=\"_blank\">driven-wood-24</a></strong> to <a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit' target=\"_blank\">https://wandb.ai/kostolansky/linear_probes_boolean_circuit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit/runs/59mw8dea' target=\"_blank\">https://wandb.ai/kostolansky/linear_probes_boolean_circuit/runs/59mw8dea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100\n",
      "Epoch 10/100\n",
      "Epoch 20/100\n",
      "Epoch 30/100\n",
      "Epoch 40/100\n",
      "Epoch 50/100\n",
      "Epoch 60/100\n",
      "Epoch 70/100\n",
      "Epoch 80/100\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>layer_0_loss</td><td>█▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>layer_1_loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>layer_2_loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▂</td></tr><tr><td>layer_3_loss</td><td>█▇▆█▇▆▆▆▆▅▅▆▅▅▄▆▄▅▃▅▄▄▃▃▄▄▃▄▃▃▃▁▃▂▃▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>layer_0_loss</td><td>0.05247</td></tr><tr><td>layer_1_loss</td><td>0.06645</td></tr><tr><td>layer_2_loss</td><td>0.19156</td></tr><tr><td>layer_3_loss</td><td>0.36819</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">driven-wood-24</strong> at: <a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit/runs/59mw8dea' target=\"_blank\">https://wandb.ai/kostolansky/linear_probes_boolean_circuit/runs/59mw8dea</a><br/> View project at: <a href='https://wandb.ai/kostolansky/linear_probes_boolean_circuit' target=\"_blank\">https://wandb.ai/kostolansky/linear_probes_boolean_circuit</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240807_172132-59mw8dea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train linear probes\n",
    "num_samples = 10000\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "linear_probes = train_linear_probes(hooked_mlp, circuit, num_samples, num_epochs, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_0': [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 69.1, 100.0, 100.0, 100.0, 100.0], 'layer_1': [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 83.8, 100.0, 100.0, 100.0, 100.0], 'layer_2': [100.0, 93.7, 93.5, 100.0, 100.0, 100.0, 100.0, 64.3, 100.0, 88.7, 100.0, 87.2], 'layer_3': [94.19999999999999, 57.49999999999999, 93.89999999999999, 95.1, 75.3, 88.6, 87.3, 57.3, 100.0, 74.6, 100.0, 87.2]}\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "accuracies = check_probe_accuracies(hooked_mlp, linear_probes, circuit, num_samples, device=\"cpu\")\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained probes\n",
    "# torch.save(linear_probes, \"linear_probes.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
